{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K0rfcrw3lkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlQAu9RJ998d",
        "colab_type": "code",
        "outputId": "06223fcf-84c7-41e7-d950-af80670c3823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/aNonY-mousx/svm.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'svm' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5yEfK9d-FCA",
        "colab_type": "code",
        "outputId": "344467ce-82da-4052-8f28-fb85bc62d0fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "!ls svm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " SSVM.ipynb\t\t\t\t        winequalityPrediction.ipynb\n",
            "'SVMTwoClassOnly(BinaryClassification).ipynb'   winequality-white.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bnJNAf6-OUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class SMOModel:\n",
        "    \"\"\"Container object for the model used for sequential minimal optimization.\"\"\"\n",
        "    \n",
        "    def __init__(self, X, y, C, kernel, alphas, b, errors):\n",
        "        self.X = X               # training data vector\n",
        "        self.y = y               # class label vector\n",
        "        self.C = C               # regularization parameter\n",
        "        self.kernel = kernel     # kernel function\n",
        "        self.alphas = alphas     # lagrange multiplier vector\n",
        "        self.b = b               # scalar bias term\n",
        "        self.errors = errors     # error cache\n",
        "        self._obj = []           # record of objective function value\n",
        "        self.m = len(self.X)     # store size of training set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNFW8slaK0pA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvr5eLq6RdTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80FYY0lcRdcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UU7jIxR2XYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs8Oql38_RTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_cQ6JR6_Ude",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_kernel(x, y, b=1):\n",
        "    \"\"\"Returns the linear combination of arrays `x` and `y` with\n",
        "    the optional bias term `b` (set to 1 by default).\"\"\"\n",
        "    \n",
        "    return np.dot(x,y.T) + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrWDv49U_d2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Objective function to optimize\n",
        "\n",
        "def objective_function(alphas, target, kernel, X_train):\n",
        "    \"\"\"Returns the SVM objective function based in the input model defined by:\n",
        "    `alphas`: vector of Lagrange multipliers\n",
        "    `target`: vector of class labels (-1 or 1) for training data\n",
        "    `kernel`: kernel function\n",
        "    `X_train`: training data for model.\"\"\"\n",
        "    \n",
        "    return np.sum(alphas) - 0.5 * np.sum(target * target * kernel(X_train, X_train) * alphas * alphas)\n",
        "\n",
        "\n",
        "# Decision function\n",
        "\n",
        "def decision_function(alphas, target, kernel, X_train, x_test, b):\n",
        "    \"\"\"Applies the SVM decision function to the input feature vectors in `x_test`.\"\"\"\n",
        "    \n",
        "    result = np.dot((alphas*target),kernel(X_train, x_test))-b\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BHUvPag_jg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def take_step(i1, i2, model):\n",
        "    \n",
        "    # Skip if chosen alphas are the same\n",
        "    if i1 == i2:\n",
        "        return 0, model\n",
        "    \n",
        "    alph1 = model.alphas[i1]\n",
        "    alph2 = model.alphas[i2]\n",
        "    y1 = model.y[i1]\n",
        "    y2 = model.y[i2]\n",
        "    E1 = model.errors[i1]\n",
        "    E2 = model.errors[i2]\n",
        "    s = y1 * y2\n",
        "    \n",
        "    # Compute L & H, the bounds on new possible alpha values\n",
        "    if (y1 != y2):\n",
        "        L = max(0, alph2 - alph1)\n",
        "        H = min(model.C, model.C + alph2 - alph1)\n",
        "    elif (y1 == y2):\n",
        "        L = max(0, alph1 + alph2 - model.C)\n",
        "        H = min(model.C, alph1 + alph2)\n",
        "    if (L == H):\n",
        "        return 0, model\n",
        "\n",
        "    # Compute kernel & 2nd derivative eta\n",
        "    k11 = model.kernel(model.X[i1], model.X[i1])\n",
        "    k12 = model.kernel(model.X[i1], model.X[i2])\n",
        "    k22 = model.kernel(model.X[i2], model.X[i2])\n",
        "    eta = 2 * k12 - k11 - k22\n",
        "    \n",
        "    # Compute new alpha 2 (a2) if eta is negative\n",
        "    if (eta < 0):\n",
        "        a2 = alph2 - y2 * (E1 - E2) / eta\n",
        "        # Clip a2 based on bounds L & H\n",
        "        if L < a2 < H:\n",
        "            a2 = a2\n",
        "        elif (a2 <= L):\n",
        "            a2 = L\n",
        "        elif (a2 >= H):\n",
        "            a2 = H\n",
        "            \n",
        "    # If eta is non-negative, move new a2 to bound with greater objective function value\n",
        "    else:\n",
        "        alphas_adj = model.alphas.copy()\n",
        "        alphas_adj[i2] = L\n",
        "        # objective function output with a2 = L\n",
        "        Lobj = objective_function(alphas_adj, model.y, model.kernel, model.X) \n",
        "        alphas_adj[i2] = H\n",
        "        # objective function output with a2 = H\n",
        "        Hobj = objective_function(alphas_adj, model.y, model.kernel, model.X)\n",
        "        if Lobj > (Hobj + eps):\n",
        "            a2 = L\n",
        "        elif Lobj < (Hobj - eps):\n",
        "            a2 = H\n",
        "        else:\n",
        "            a2 = alph2\n",
        "            \n",
        "    # Push a2 to 0 or C if very close\n",
        "    if a2 < 1e-8:\n",
        "        a2 = 0.0\n",
        "    elif a2 > (model.C - 1e-8):\n",
        "        a2 = model.C\n",
        "    \n",
        "    # If examples can't be optimized within epsilon (eps), skip this pair\n",
        "    if (np.abs(a2 - alph2) < eps * (a2 + alph2 + eps)):\n",
        "        return 0, model\n",
        "    \n",
        "    # Calculate new alpha 1 (a1)\n",
        "    a1 = alph1 + s * (alph2 - a2)\n",
        "    \n",
        "    # Update threshold b to reflect newly calculated alphas\n",
        "    # Calculate both possible thresholds\n",
        "    b1 = E1 + y1 * (a1 - alph1) * k11 + y2 * (a2 - alph2) * k12 + model.b\n",
        "    b2 = E2 + y1 * (a1 - alph1) * k12 + y2 * (a2 - alph2) * k22 + model.b\n",
        "    \n",
        "    # Set new threshold based on if a1 or a2 is bound by L and/or H\n",
        "    if 0 < a1 and a1 < C:\n",
        "        b_new = b1\n",
        "    elif 0 < a2 and a2 < C:\n",
        "        b_new = b2\n",
        "    # Average thresholds if both are bound\n",
        "    else:\n",
        "        b_new = (b1 + b2) * 0.5\n",
        "\n",
        "    # Update model object with new alphas & threshold\n",
        "    model.alphas[i1] = a1\n",
        "    model.alphas[i2] = a2\n",
        "    \n",
        "    # Update error cache\n",
        "    # Error cache for optimized alphas is set to 0 if they're unbound\n",
        "    for index, alph in zip([i1, i2], [a1, a2]):\n",
        "        if 0.0 < alph < model.C:\n",
        "            model.errors[index] = 0.0\n",
        "    \n",
        "    # Set non-optimized errors based on equation 12.11 in Platt's book\n",
        "    non_opt = [n for n in range(model.m) if (n != i1 and n != i2)]\n",
        "    model.errors[non_opt] = model.errors[non_opt] +\\\n",
        "                            y1*(a1 - alph1)*model.kernel(model.X[i1], model.X[non_opt]) +\\\n",
        "                            y2*(a2 - alph2)*model.kernel(model.X[i2], model.X[non_opt]) + model.b - b_new\n",
        "    \n",
        "    # Update model threshold\n",
        "    model.b = b_new\n",
        "    \n",
        "    return 1, model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VjqTaHZ_uuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def examine_example(i2, model):\n",
        "    \n",
        "    y2 = model.y[i2]\n",
        "    alph2 = model.alphas[i2]\n",
        "    E2 = model.errors[i2]\n",
        "    r2 = E2 * y2\n",
        "\n",
        "    # Proceed if error is within specified tolerance (tol)\n",
        "    if ((r2 < -tol and alph2 < model.C) or (r2 > tol and alph2 > 0)):\n",
        "        \n",
        "        if len(model.alphas[(model.alphas != 0) & (model.alphas != model.C)]) > 1:\n",
        "            # Use 2nd choice heuristic is choose max difference in error\n",
        "            if model.errors[i2] > 0:\n",
        "                i1 = np.argmin(model.errors)\n",
        "            elif model.errors[i2] <= 0:\n",
        "                i1 = np.argmax(model.errors)\n",
        "            step_result, model = take_step(i1, i2, model)\n",
        "            if step_result:\n",
        "                return 1, model\n",
        "            \n",
        "        # Loop through non-zero and non-C alphas, starting at a random point\n",
        "        for i1 in np.roll(np.where((model.alphas != 0) & (model.alphas != model.C))[0],\n",
        "                          np.random.choice(np.arange(model.m))):\n",
        "            step_result, model = take_step(i1, i2, model)\n",
        "            if step_result:\n",
        "                return 1, model\n",
        "        \n",
        "        # loop through all alphas, starting at a random point\n",
        "        for i1 in np.roll(np.arange(model.m), np.random.choice(np.arange(model.m))):\n",
        "            step_result, model = take_step(i1, i2, model)\n",
        "            if step_result:\n",
        "                return 1, model\n",
        "    \n",
        "    return 0, model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz-VUtmS_zLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model):\n",
        "    \n",
        "    numChanged = 0\n",
        "    examineAll = 1\n",
        "    iterations = 0\n",
        "    \n",
        "    while(numChanged > 0) or (examineAll):\n",
        "        iterations += 1\n",
        "#         print(iterations)\n",
        "        if(iterations>5000):\n",
        "            break\n",
        "        numChanged = 0\n",
        "        if examineAll:\n",
        "            # loop over all training examples\n",
        "            for i in range(model.alphas.shape[0]):\n",
        "                examine_result, model = examine_example(i, model)\n",
        "                numChanged += examine_result\n",
        "                if examine_result:\n",
        "                    obj_result = objective_function(model.alphas, model.y, model.kernel, model.X)\n",
        "                    model._obj.append(obj_result)\n",
        "        else:\n",
        "            # loop over examples where alphas are not already at their limits\n",
        "            for i in np.where((model.alphas != 0) & (model.alphas != model.C))[0]:\n",
        "                examine_result, model = examine_example(i, model)\n",
        "                numChanged += examine_result\n",
        "                if examine_result:\n",
        "                    obj_result = objective_function(model.alphas, model.y, model.kernel, model.X)\n",
        "                    model._obj.append(obj_result)\n",
        "        if examineAll == 1:\n",
        "            examineAll = 0\n",
        "        elif numChanged == 0:\n",
        "            examineAll = 1\n",
        "        \n",
        "    return model\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFdyUPd1nF-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set model parameters and initial values\n",
        "C = 1.2\n",
        "#m = len(X_train)\n",
        "#initial_alphas = np.zeros(m)\n",
        "initial_b = 0.0\n",
        "\n",
        "# Set tolerances\n",
        "tol = 0.01 # error tolerance\n",
        "eps = 0.01 # alpha tolerance\n",
        "\n",
        "# Instantiate model\n",
        "#model = SMOModel(X_train, y_train, C, linear_kernel,initial_alphas, initial_b, np.zeros(m))\n",
        "#output = train(model)\n",
        "\n",
        "# For prediction\n",
        "#predictions = decision_function(model.alphas, model.y, model.kernel,model.X, X_test, model.b)\n",
        "#print(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqCybS_LS4lf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr_EEVf6_2HI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading and preprocessing data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzylP0Ls4G15",
        "colab_type": "code",
        "outputId": "58c5d887-6e64-45b8-a466-03b65384c189",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploadeddata = files.upload()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0f3e8568-46ca-4f86-9e7c-62075ecb5601\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-0f3e8568-46ca-4f86-9e7c-62075ecb5601\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving winequality-red.csv to winequality-red (4).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlu4Mv495J6h",
        "colab_type": "code",
        "outputId": "748abefc-8114-44eb-a09a-6938fd7ab475",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " sample_data\t\t   'winequality-red (2).csv'   winequality-red.csv\n",
            " svm\t\t\t   'winequality-red (3).csv'\n",
            "'winequality-red (1).csv'  'winequality-red (4).csv'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbyiYrKHAA1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "redwine = pd.read_csv('winequality-red.csv',delimiter=';')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inhF1jue74Wx",
        "colab_type": "code",
        "outputId": "0205dbaf-df09-4f2c-a5d8-ab9be6657d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "redwine.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
              "0            7.4              0.70         0.00  ...       0.56      9.4        5\n",
              "1            7.8              0.88         0.00  ...       0.68      9.8        5\n",
              "2            7.8              0.76         0.04  ...       0.65      9.8        5\n",
              "3           11.2              0.28         0.56  ...       0.58      9.8        6\n",
              "4            7.4              0.70         0.00  ...       0.56      9.4        5\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDOCreJy8CMy",
        "colab_type": "code",
        "outputId": "ee9f443c-a5ef-4f9b-b5b5-67f88c8b5a9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "#Here we see that fixed acidity does not give any specification to classify the quality.\n",
        "fig = plt.figure(figsize = (10,6))\n",
        "sns.barplot(x = 'quality', y = 'fixed acidity', data = df)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-004cd458199e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'quality'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'fixed acidity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzSQvPBF8Vjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "redwine.drop([\"free sulfur dioxide\",\"citric acid\",\"chlorides\",\"density\"],axis=1,inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT5PhQ6Q8Oea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDtFxBNaifn9",
        "colab_type": "code",
        "outputId": "39d3c38f-f052-4d7d-c0c2-1af80d1a1ebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#checking duplicated values\n",
        "sum(redwine.duplicated())\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "240"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtfGpTCeUKnF",
        "colab_type": "code",
        "outputId": "b1167654-7b20-413d-e94e-643ed6437dd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "redwine =redwine.drop_duplicates()\n",
        "redwine.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1359, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtAU0Yfkitqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "redwine = redwine.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjGCOgoJAFf6",
        "colab_type": "code",
        "outputId": "884cf59d-8e1e-4aa2-a424-b155aed6dc98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "quality = redwine[\"quality\"].values\n",
        "category = []\n",
        "for num in quality:\n",
        "    if num < 5:\n",
        "        category.append(\"Low Quality\")\n",
        "    elif num >7:\n",
        "        category.append(\"High Quality\")\n",
        "    else:\n",
        "        category.append(\"Normal Quality\")\n",
        "len(category)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1359"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW07Bhe7UZPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "category = pd.DataFrame(data=category, columns=[\"category\"])\n",
        "data = pd.concat([redwine, category], axis=1)\n",
        "\n",
        "data.drop(columns=\"quality\", axis=1, inplace=True)\n",
        "X = data.iloc[:, :-1].values\n",
        "y= data.iloc[:, -1].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr8dtRcXUkVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder_y = LabelEncoder()\n",
        "y = labelencoder_y.fit_transform(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZOQ2VJZUlf5",
        "colab_type": "code",
        "outputId": "cf7b5b50-9fe3-4d06-eeb4-cff3ffca0809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labelencoder_y.transform([\"High Quality\",\"Low Quality\", \"Normal Quality\"])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMxYwm9UUlnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn import preprocessing\n",
        "# #normalizing\n",
        "# normalized_X= preprocessing.normalize(X)\n",
        "# standardized_X = preprocessing.scale(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhrkAV5HkmDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# x_train,x_test,y_train,y_test = train_test_split(standardized_X,y,test_size=0.2,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLMvVq8kLx44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVd7jIunUjiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z1 = pd.DataFrame(x_test.copy())\n",
        "z2 = pd.DataFrame(y_test.copy())\n",
        "dataframeForTest = pd.concat([z1,z2], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhvUHsPlALFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# # Applying Standard scaling to get optimized result\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.fit_transform(x_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoiFOIX-AOb8",
        "colab_type": "code",
        "outputId": "91cd1a3c-d45d-4e09-cd9c-7f2a11b97b78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>1.9</td>\n",
              "      <td>34.0</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.880</td>\n",
              "      <td>2.6</td>\n",
              "      <td>67.0</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.760</td>\n",
              "      <td>2.3</td>\n",
              "      <td>54.0</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.280</td>\n",
              "      <td>1.9</td>\n",
              "      <td>60.0</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.660</td>\n",
              "      <td>1.8</td>\n",
              "      <td>40.0</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>7.9</td>\n",
              "      <td>0.600</td>\n",
              "      <td>1.6</td>\n",
              "      <td>59.0</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.4</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7.3</td>\n",
              "      <td>0.650</td>\n",
              "      <td>1.2</td>\n",
              "      <td>21.0</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.47</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.580</td>\n",
              "      <td>2.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>3.36</td>\n",
              "      <td>0.57</td>\n",
              "      <td>9.5</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7.5</td>\n",
              "      <td>0.500</td>\n",
              "      <td>6.1</td>\n",
              "      <td>102.0</td>\n",
              "      <td>3.35</td>\n",
              "      <td>0.80</td>\n",
              "      <td>10.5</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6.7</td>\n",
              "      <td>0.580</td>\n",
              "      <td>1.8</td>\n",
              "      <td>65.0</td>\n",
              "      <td>3.28</td>\n",
              "      <td>0.54</td>\n",
              "      <td>9.2</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5.6</td>\n",
              "      <td>0.615</td>\n",
              "      <td>1.6</td>\n",
              "      <td>59.0</td>\n",
              "      <td>3.58</td>\n",
              "      <td>0.52</td>\n",
              "      <td>9.9</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.610</td>\n",
              "      <td>1.6</td>\n",
              "      <td>29.0</td>\n",
              "      <td>3.26</td>\n",
              "      <td>1.56</td>\n",
              "      <td>9.1</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>8.9</td>\n",
              "      <td>0.620</td>\n",
              "      <td>3.8</td>\n",
              "      <td>145.0</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.88</td>\n",
              "      <td>9.2</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>8.9</td>\n",
              "      <td>0.620</td>\n",
              "      <td>3.9</td>\n",
              "      <td>148.0</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.93</td>\n",
              "      <td>9.2</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>8.5</td>\n",
              "      <td>0.280</td>\n",
              "      <td>1.8</td>\n",
              "      <td>103.0</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.75</td>\n",
              "      <td>10.5</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>8.1</td>\n",
              "      <td>0.560</td>\n",
              "      <td>1.7</td>\n",
              "      <td>56.0</td>\n",
              "      <td>3.11</td>\n",
              "      <td>1.28</td>\n",
              "      <td>9.3</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.590</td>\n",
              "      <td>4.4</td>\n",
              "      <td>29.0</td>\n",
              "      <td>3.38</td>\n",
              "      <td>0.50</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Low Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>7.9</td>\n",
              "      <td>0.320</td>\n",
              "      <td>1.8</td>\n",
              "      <td>56.0</td>\n",
              "      <td>3.04</td>\n",
              "      <td>1.08</td>\n",
              "      <td>9.2</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>8.9</td>\n",
              "      <td>0.220</td>\n",
              "      <td>1.8</td>\n",
              "      <td>60.0</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.53</td>\n",
              "      <td>9.4</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>7.6</td>\n",
              "      <td>0.390</td>\n",
              "      <td>2.3</td>\n",
              "      <td>71.0</td>\n",
              "      <td>3.52</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.7</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>7.9</td>\n",
              "      <td>0.430</td>\n",
              "      <td>1.6</td>\n",
              "      <td>37.0</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.91</td>\n",
              "      <td>9.5</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>8.5</td>\n",
              "      <td>0.490</td>\n",
              "      <td>2.3</td>\n",
              "      <td>67.0</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.53</td>\n",
              "      <td>9.4</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>6.9</td>\n",
              "      <td>0.400</td>\n",
              "      <td>2.4</td>\n",
              "      <td>40.0</td>\n",
              "      <td>3.43</td>\n",
              "      <td>0.63</td>\n",
              "      <td>9.7</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.390</td>\n",
              "      <td>1.4</td>\n",
              "      <td>23.0</td>\n",
              "      <td>3.34</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.3</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>7.6</td>\n",
              "      <td>0.410</td>\n",
              "      <td>1.8</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.28</td>\n",
              "      <td>0.59</td>\n",
              "      <td>9.5</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>7.1</td>\n",
              "      <td>0.710</td>\n",
              "      <td>1.9</td>\n",
              "      <td>35.0</td>\n",
              "      <td>3.47</td>\n",
              "      <td>0.55</td>\n",
              "      <td>9.4</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.645</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>3.38</td>\n",
              "      <td>0.59</td>\n",
              "      <td>9.8</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>6.7</td>\n",
              "      <td>0.675</td>\n",
              "      <td>2.4</td>\n",
              "      <td>82.0</td>\n",
              "      <td>3.35</td>\n",
              "      <td>0.54</td>\n",
              "      <td>10.1</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>6.9</td>\n",
              "      <td>0.685</td>\n",
              "      <td>2.5</td>\n",
              "      <td>37.0</td>\n",
              "      <td>3.46</td>\n",
              "      <td>0.57</td>\n",
              "      <td>10.6</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>8.3</td>\n",
              "      <td>0.655</td>\n",
              "      <td>2.3</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.17</td>\n",
              "      <td>0.66</td>\n",
              "      <td>9.8</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1329</th>\n",
              "      <td>6.7</td>\n",
              "      <td>0.160</td>\n",
              "      <td>2.1</td>\n",
              "      <td>52.0</td>\n",
              "      <td>3.34</td>\n",
              "      <td>0.71</td>\n",
              "      <td>11.2</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1330</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.560</td>\n",
              "      <td>1.6</td>\n",
              "      <td>42.0</td>\n",
              "      <td>3.34</td>\n",
              "      <td>0.59</td>\n",
              "      <td>9.2</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1331</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.510</td>\n",
              "      <td>1.9</td>\n",
              "      <td>34.0</td>\n",
              "      <td>3.48</td>\n",
              "      <td>0.57</td>\n",
              "      <td>11.5</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1332</th>\n",
              "      <td>6.4</td>\n",
              "      <td>0.360</td>\n",
              "      <td>2.2</td>\n",
              "      <td>35.0</td>\n",
              "      <td>3.37</td>\n",
              "      <td>0.93</td>\n",
              "      <td>12.4</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>6.4</td>\n",
              "      <td>0.380</td>\n",
              "      <td>2.2</td>\n",
              "      <td>25.0</td>\n",
              "      <td>3.44</td>\n",
              "      <td>0.65</td>\n",
              "      <td>11.1</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>7.3</td>\n",
              "      <td>0.690</td>\n",
              "      <td>2.2</td>\n",
              "      <td>104.0</td>\n",
              "      <td>3.33</td>\n",
              "      <td>0.51</td>\n",
              "      <td>9.5</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.580</td>\n",
              "      <td>2.4</td>\n",
              "      <td>50.0</td>\n",
              "      <td>3.58</td>\n",
              "      <td>0.67</td>\n",
              "      <td>12.5</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>5.6</td>\n",
              "      <td>0.310</td>\n",
              "      <td>13.9</td>\n",
              "      <td>92.0</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.48</td>\n",
              "      <td>10.5</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>7.5</td>\n",
              "      <td>0.520</td>\n",
              "      <td>2.2</td>\n",
              "      <td>20.0</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.64</td>\n",
              "      <td>11.8</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1338</th>\n",
              "      <td>8.0</td>\n",
              "      <td>0.300</td>\n",
              "      <td>1.6</td>\n",
              "      <td>29.0</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.78</td>\n",
              "      <td>10.8</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1339</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.700</td>\n",
              "      <td>5.1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>3.54</td>\n",
              "      <td>0.60</td>\n",
              "      <td>11.9</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1340</th>\n",
              "      <td>6.8</td>\n",
              "      <td>0.670</td>\n",
              "      <td>1.8</td>\n",
              "      <td>20.0</td>\n",
              "      <td>3.42</td>\n",
              "      <td>0.67</td>\n",
              "      <td>11.3</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1341</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.560</td>\n",
              "      <td>1.7</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.54</td>\n",
              "      <td>0.60</td>\n",
              "      <td>11.3</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1342</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.350</td>\n",
              "      <td>2.4</td>\n",
              "      <td>26.0</td>\n",
              "      <td>3.36</td>\n",
              "      <td>0.60</td>\n",
              "      <td>11.9</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1343</th>\n",
              "      <td>6.1</td>\n",
              "      <td>0.715</td>\n",
              "      <td>2.6</td>\n",
              "      <td>27.0</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.50</td>\n",
              "      <td>11.9</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1344</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.460</td>\n",
              "      <td>2.1</td>\n",
              "      <td>98.0</td>\n",
              "      <td>3.33</td>\n",
              "      <td>0.62</td>\n",
              "      <td>9.8</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1345</th>\n",
              "      <td>6.7</td>\n",
              "      <td>0.320</td>\n",
              "      <td>2.4</td>\n",
              "      <td>34.0</td>\n",
              "      <td>3.29</td>\n",
              "      <td>0.80</td>\n",
              "      <td>11.6</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1346</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.390</td>\n",
              "      <td>2.6</td>\n",
              "      <td>48.0</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.84</td>\n",
              "      <td>11.5</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1347</th>\n",
              "      <td>7.5</td>\n",
              "      <td>0.310</td>\n",
              "      <td>2.4</td>\n",
              "      <td>60.0</td>\n",
              "      <td>3.34</td>\n",
              "      <td>0.85</td>\n",
              "      <td>11.4</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1348</th>\n",
              "      <td>5.8</td>\n",
              "      <td>0.610</td>\n",
              "      <td>1.8</td>\n",
              "      <td>28.0</td>\n",
              "      <td>3.55</td>\n",
              "      <td>0.66</td>\n",
              "      <td>10.9</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1349</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.660</td>\n",
              "      <td>2.5</td>\n",
              "      <td>102.0</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0.78</td>\n",
              "      <td>12.8</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1350</th>\n",
              "      <td>6.6</td>\n",
              "      <td>0.725</td>\n",
              "      <td>7.8</td>\n",
              "      <td>79.0</td>\n",
              "      <td>3.29</td>\n",
              "      <td>0.54</td>\n",
              "      <td>9.2</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1351</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.550</td>\n",
              "      <td>1.8</td>\n",
              "      <td>35.0</td>\n",
              "      <td>3.32</td>\n",
              "      <td>0.82</td>\n",
              "      <td>11.6</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1352</th>\n",
              "      <td>5.4</td>\n",
              "      <td>0.740</td>\n",
              "      <td>1.7</td>\n",
              "      <td>26.0</td>\n",
              "      <td>3.67</td>\n",
              "      <td>0.56</td>\n",
              "      <td>11.6</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1353</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.510</td>\n",
              "      <td>2.3</td>\n",
              "      <td>40.0</td>\n",
              "      <td>3.42</td>\n",
              "      <td>0.75</td>\n",
              "      <td>11.0</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1354</th>\n",
              "      <td>6.8</td>\n",
              "      <td>0.620</td>\n",
              "      <td>1.9</td>\n",
              "      <td>38.0</td>\n",
              "      <td>3.42</td>\n",
              "      <td>0.82</td>\n",
              "      <td>9.5</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1355</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.600</td>\n",
              "      <td>2.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>3.45</td>\n",
              "      <td>0.58</td>\n",
              "      <td>10.5</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1356</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.550</td>\n",
              "      <td>2.2</td>\n",
              "      <td>51.0</td>\n",
              "      <td>3.52</td>\n",
              "      <td>0.76</td>\n",
              "      <td>11.2</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1357</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.645</td>\n",
              "      <td>2.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.71</td>\n",
              "      <td>10.2</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1358</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.310</td>\n",
              "      <td>3.6</td>\n",
              "      <td>42.0</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.66</td>\n",
              "      <td>11.0</td>\n",
              "      <td>Normal Quality</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1359 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      fixed acidity  volatile acidity  ...  alcohol        category\n",
              "0               7.4             0.700  ...      9.4  Normal Quality\n",
              "1               7.8             0.880  ...      9.8  Normal Quality\n",
              "2               7.8             0.760  ...      9.8  Normal Quality\n",
              "3              11.2             0.280  ...      9.8  Normal Quality\n",
              "4               7.4             0.660  ...      9.4  Normal Quality\n",
              "5               7.9             0.600  ...      9.4  Normal Quality\n",
              "6               7.3             0.650  ...     10.0  Normal Quality\n",
              "7               7.8             0.580  ...      9.5  Normal Quality\n",
              "8               7.5             0.500  ...     10.5  Normal Quality\n",
              "9               6.7             0.580  ...      9.2  Normal Quality\n",
              "10              5.6             0.615  ...      9.9  Normal Quality\n",
              "11              7.8             0.610  ...      9.1  Normal Quality\n",
              "12              8.9             0.620  ...      9.2  Normal Quality\n",
              "13              8.9             0.620  ...      9.2  Normal Quality\n",
              "14              8.5             0.280  ...     10.5  Normal Quality\n",
              "15              8.1             0.560  ...      9.3  Normal Quality\n",
              "16              7.4             0.590  ...      9.0     Low Quality\n",
              "17              7.9             0.320  ...      9.2  Normal Quality\n",
              "18              8.9             0.220  ...      9.4  Normal Quality\n",
              "19              7.6             0.390  ...      9.7  Normal Quality\n",
              "20              7.9             0.430  ...      9.5  Normal Quality\n",
              "21              8.5             0.490  ...      9.4  Normal Quality\n",
              "22              6.9             0.400  ...      9.7  Normal Quality\n",
              "23              6.3             0.390  ...      9.3  Normal Quality\n",
              "24              7.6             0.410  ...      9.5  Normal Quality\n",
              "25              7.1             0.710  ...      9.4  Normal Quality\n",
              "26              7.8             0.645  ...      9.8  Normal Quality\n",
              "27              6.7             0.675  ...     10.1  Normal Quality\n",
              "28              6.9             0.685  ...     10.6  Normal Quality\n",
              "29              8.3             0.655  ...      9.8  Normal Quality\n",
              "...             ...               ...  ...      ...             ...\n",
              "1329            6.7             0.160  ...     11.2  Normal Quality\n",
              "1330            7.0             0.560  ...      9.2  Normal Quality\n",
              "1331            6.2             0.510  ...     11.5  Normal Quality\n",
              "1332            6.4             0.360  ...     12.4  Normal Quality\n",
              "1333            6.4             0.380  ...     11.1  Normal Quality\n",
              "1334            7.3             0.690  ...      9.5  Normal Quality\n",
              "1335            6.0             0.580  ...     12.5  Normal Quality\n",
              "1336            5.6             0.310  ...     10.5  Normal Quality\n",
              "1337            7.5             0.520  ...     11.8  Normal Quality\n",
              "1338            8.0             0.300  ...     10.8  Normal Quality\n",
              "1339            6.2             0.700  ...     11.9  Normal Quality\n",
              "1340            6.8             0.670  ...     11.3  Normal Quality\n",
              "1341            6.2             0.560  ...     11.3  Normal Quality\n",
              "1342            7.4             0.350  ...     11.9  Normal Quality\n",
              "1343            6.1             0.715  ...     11.9  Normal Quality\n",
              "1344            6.2             0.460  ...      9.8  Normal Quality\n",
              "1345            6.7             0.320  ...     11.6  Normal Quality\n",
              "1346            7.2             0.390  ...     11.5  Normal Quality\n",
              "1347            7.5             0.310  ...     11.4  Normal Quality\n",
              "1348            5.8             0.610  ...     10.9  Normal Quality\n",
              "1349            7.2             0.660  ...     12.8  Normal Quality\n",
              "1350            6.6             0.725  ...      9.2  Normal Quality\n",
              "1351            6.3             0.550  ...     11.6  Normal Quality\n",
              "1352            5.4             0.740  ...     11.6  Normal Quality\n",
              "1353            6.3             0.510  ...     11.0  Normal Quality\n",
              "1354            6.8             0.620  ...      9.5  Normal Quality\n",
              "1355            6.2             0.600  ...     10.5  Normal Quality\n",
              "1356            5.9             0.550  ...     11.2  Normal Quality\n",
              "1357            5.9             0.645  ...     10.2  Normal Quality\n",
              "1358            6.0             0.310  ...     11.0  Normal Quality\n",
              "\n",
              "[1359 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FG6_YfDARhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.under_sampling import ClusterCentroids\n",
        "from imblearn.over_sampling import SMOTE\n",
        "# under sample \"2\" ；\n",
        "# over sample \"1\", \"0\"\n",
        "smt = ClusterCentroids(ratio={2:400})\n",
        "X_sm, y_sm = smt.fit_sample(x_train, y_train)\n",
        "smt2 = SMOTE(ratio={0: 400, 1: 400})\n",
        "x_sm2, y_sm2 = smt2.fit_sample(X_sm, y_sm)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7qDJ5GbXdkx",
        "colab_type": "code",
        "outputId": "82f4bfc9-557e-4ad1-9072-ea25fc52b7d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "\n",
        "\n",
        "pip install six"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-35-cdc4852d4386>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    pip install six\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEinxxyIZ247",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4156c305-ffac-4c22-c508-262519dae3ed"
      },
      "source": [
        "y_sm2.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPl22GH4AUAQ",
        "colab_type": "code",
        "outputId": "b7891bf9-c9e3-4c55-873d-e084f4e67851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.unique(y_train)  ## purai array ma unique values haru matrai select garne"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfAmXnmQXrJ4",
        "colab_type": "code",
        "outputId": "b1fd81da-deba-4a23-f672-78bc04630ef9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.unique(y_sm2, return_counts=True)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2]), array([400, 400, 400]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk9N9AujAa-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Set model parameters and initial values\n",
        "C = 1.2\n",
        "m = len(x_train)\n",
        "initial_alphas = np.zeros(m)\n",
        "initial_b = 0.0\n",
        "# Set tolerances\n",
        "tol = 0.01 # error tolerance\n",
        "eps = 0.01 # alpha tolerance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhm4z9UAAenc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlvEE6jyAmYr",
        "colab_type": "text"
      },
      "source": [
        "Start the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk6Ff-alAhmC",
        "colab_type": "code",
        "outputId": "3ee4da42-039e-4f0c-9d5f-5c47a1172d4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "labels = np.unique(y_train)\n",
        "classifiers=[]\n",
        "# iterate over all labels ..\n",
        "for label in labels:# Set model parameters and initial values\n",
        "    # Set model parameters and initial values\n",
        "    C = 1.2\n",
        "    m = len(x_train)\n",
        "    initial_alphas = np.zeros(m)\n",
        "    initial_b = 0.0\n",
        "# Set tolerances\n",
        "    tol = 0.01 # error tolerance\n",
        "    eps = 0.01 # alpha tolerance \n",
        "    print (\"Classifier\",label,\" vs Rest\")\n",
        "    yi = np.array(y_train)\n",
        "    yi[yi != label] = -1.0\n",
        "    yi[yi == label] = 1.0\n",
        "    print(np.unique(yi))\n",
        "    print(yi.shape,x_train.shape)\n",
        "    model = SMOModel(x_train, yi, C,linear_kernel,initial_alphas, initial_b, np.zeros(m))\n",
        "    # Initialize error cache\n",
        "    initial_error = decision_function(model.alphas, model.y, model.kernel,\n",
        "                                  model.X, model.X, model.b) - model.y\n",
        "    model.errors = initial_error\n",
        "    output = train(model)\n",
        "    classifiers.append(copy.deepcopy(model))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classifier 0  vs Rest\n",
            "[-1  1]\n",
            "(1087,) (1087, 7)\n",
            "Classifier 1  vs Rest\n",
            "[-1  1]\n",
            "(1087,) (1087, 7)\n",
            "Classifier 2  vs Rest\n",
            "[-1  1]\n",
            "(1087,) (1087, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MGFzofyFIrX",
        "colab_type": "code",
        "outputId": "814513d9-98ed-483a-9f04-099abe90c0f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "print(\"Total no of classifier created \",len(classifiers))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no of classifier created  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEVbIv4OAoD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PREDICTING PART"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZNzz4onVA3A",
        "colab_type": "code",
        "outputId": "c4292679-7769-485d-ac28-f5d1d0f22c10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "labels"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxt3ay0DVDhO",
        "colab_type": "code",
        "outputId": "94682d06-a75d-4836-d165-7c4eb6fa62ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# we have to return prediction for x_test array of 11 features Dimension[x,11]\n",
        "n = x_test.shape[0]\n",
        "scores = np.zeros((n, len(labels)))\n",
        "scores.shape #each row of scores will store score(probability) for each label(class) and we will return largest one"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(272, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQfMniFBVG33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for i in range(len(labels)):\n",
        "    model = classifiers[i]\n",
        "    scores[:,i] = decision_function(model.alphas, model.y, model.kernel,model.X, x_test, model.b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXYrYZXNMcQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYy96GhUVKb3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "c7bbb9b4-45aa-44fd-d8ff-73a9bd0248ad"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "predictions = np.argmax(scores, axis=1)\n",
        "#scores\n",
        "predictions\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL1ztJT4Nham",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b1ccd951-7930-4462-c11f-678925d474e8"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, predictedLabels)\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   3],\n",
              "       [  0,   1,  14],\n",
              "       [  0,   1, 253]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q0N5QxGmCEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFnRG9C2Nhi8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "0e42e17b-c71e-4750-9eda-4413794a957a"
      },
      "source": [
        "cm =confusion_matrix(y_test,predictedLabels)\n",
        "print(cm)\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax, fmt='g'); #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title(' Testing after resample Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['high', 'low','normal']); ax.yaxis.set_ticklabels(['high', 'low','normal']);\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   3]\n",
            " [  0   1  14]\n",
            " [  0   1 253]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEWCAYAAABG030jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKVBSlOiNw_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0OG8mfnOmQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8Pl_q9YOmaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq_rP-uvVNa0",
        "colab_type": "code",
        "outputId": "e71483a6-16b6-4e04-ea99-af0c6f61c16c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "for prediction in predictions:\n",
        "    print(labels[prediction])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPou0cOaVPqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictedLabels =[]\n",
        "for prediction in predictions:\n",
        "    predictedLabels.append(labels[prediction])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ8fC2HdVTiL",
        "colab_type": "code",
        "outputId": "438753f2-9670-422a-b385-e848b20c7182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "\n",
        "## Accuracy Measure\n",
        "correct=0\n",
        "for i in range(len(predictedLabels)):\n",
        "    if(predictedLabels[i]==y_test[i]):\n",
        "        correct+=1\n",
        "print(\"Accuracy : \",correct,\" out of \",len(predictedLabels))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  254  out of  272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-xnLJZgVWSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "# cmatrix = confusion_matrix(y_test[i],predictedLabels)\n",
        "# cmatrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63wZdPIwrKId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred=output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBmBQW4aJhGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Set model parameters and initial values\n",
        "C = 1.2\n",
        "m = len(x_sm2)\n",
        "initial_alphas = np.zeros(m)\n",
        "initial_b = 0.0\n",
        "# Set tolerances\n",
        "tol = 0.01 # error tolerance\n",
        "eps = 0.01 # alpha tolerance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KORNd_om4mt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Daatmuu6LnnZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "87adced7-772d-458f-a55a-d265f0b1f741"
      },
      "source": [
        "labels = np.unique(y_sm2)\n",
        "classifiers=[]\n",
        "# iterate over all labels ..\n",
        "for label in labels:# Set model parameters and initial values\n",
        "    # Set model parameters and initial values\n",
        "    C = 1.2\n",
        "    m = len(x_sm2)\n",
        "    initial_alphas = np.zeros(m)\n",
        "    initial_b = 0.0\n",
        "# Set tolerances\n",
        "    tol = 0.01 # error tolerance\n",
        "    eps = 0.01 # alpha tolerance \n",
        "    print (\"Classifier\",label,\" vs Rest\")\n",
        "    yi = np.array(y_sm2)\n",
        "    yi[yi != label] = -1.0\n",
        "    yi[yi == label] = 1.0\n",
        "    print(np.unique(yi))\n",
        "    print(yi.shape,x_sm2.shape)\n",
        "    model = SMOModel(x_sm2, yi, C,linear_kernel,initial_alphas, initial_b, np.zeros(m))\n",
        "    # Initialize error cache\n",
        "    initial_error = decision_function(model.alphas, model.y, model.kernel,\n",
        "                                  model.X, model.X, model.b) - model.y\n",
        "    model.errors = initial_error\n",
        "    output = train(model)\n",
        "    classifiers.append(copy.deepcopy(model))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classifier 0  vs Rest\n",
            "[-1  1]\n",
            "(1200,) (1200, 7)\n",
            "Classifier 1  vs Rest\n",
            "[-1  1]\n",
            "(1200,) (1200, 7)\n",
            "Classifier 2  vs Rest\n",
            "[-1  1]\n",
            "(1200,) (1200, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkIyALn17g_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "d6e86f6a-f785-4316-ce03-8681d4bdcb57"
      },
      "source": [
        "\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-afcb98cc8309>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"traning accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"testing accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'SMOModel' object has no attribute 'score'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgNLvCwr7q8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for i in range(len(labels)):\n",
        "    model = classifiers[i]\n",
        "    scores[:,i] = decision_function(model.alphas, model.y, model.kernel,model.X, x_test, model.b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP_iRDfNtOh9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "937e04b0-7cd6-4861-dee9-5b270601ff7e"
      },
      "source": [
        "\n",
        "predictions = np.argmax(scores, axis=1)\n",
        "#scores\n",
        "predictions\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 0, 1, 1, 0, 2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 0, 2, 1, 2, 2, 0,\n",
              "       2, 1, 0, 2, 2, 1, 1, 1, 2, 0, 2, 1, 1, 0, 2, 1, 1, 2, 1, 2, 0, 2,\n",
              "       1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 0, 2, 1, 1, 2, 0, 2, 2, 1, 2, 2, 2,\n",
              "       2, 1, 2, 2, 2, 0, 2, 2, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 1, 0, 1, 2,\n",
              "       0, 2, 2, 1, 1, 2, 1, 2, 1, 0, 0, 2, 2, 1, 2, 1, 1, 2, 2, 1, 0, 0,\n",
              "       1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 0, 2, 1, 2, 1, 2, 2, 1,\n",
              "       2, 2, 2, 1, 0, 2, 0, 1, 1, 2, 0, 0, 2, 2, 0, 1, 2, 1, 2, 0, 2, 1,\n",
              "       2, 1, 2, 1, 0, 0, 2, 1, 1, 2, 2, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
              "       2, 2, 2, 0, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 0, 2, 1, 2, 0, 1,\n",
              "       0, 2, 2, 0, 1, 0, 2, 2, 1, 2, 2, 1, 0, 0, 2, 2, 0, 1, 0, 0, 2, 0,\n",
              "       1, 2, 2, 2, 1, 2, 0, 2, 2, 2, 1, 2, 2, 2, 0, 0, 2, 2, 1, 1, 2, 1,\n",
              "       1, 1, 0, 2, 2, 0, 1, 0, 2, 2, 0, 0, 1, 2, 1, 1, 2, 1, 2, 1, 2, 2,\n",
              "       2, 1, 2, 2, 1, 2, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12kG7h0Xtllx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictedLabels =[]\n",
        "for prediction in predictions:\n",
        "    predictedLabels.append(labels[prediction])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2-kckdVtmTY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89de097c-470d-4cd9-f3e1-19fb41fda554"
      },
      "source": [
        "## Accuracy Measure\n",
        "correct=0\n",
        "for i in range(len(predictedLabels)):\n",
        "    if(predictedLabels[i]==y_test[i]):\n",
        "        correct+=1\n",
        "print(\"Accuracy : \",correct,\" out of \",len(predictedLabels))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  140  out of  272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLzYaqTLtTXn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "1fd089f9-aa72-40ad-c5f7-04184f8c995b"
      },
      "source": [
        "cm2 =confusion_matrix(y_test,predictedLabels)\n",
        "print(cm2)\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm2, annot=True, ax = ax, fmt='g'); #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title(' Testing after resample Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['high', 'low','normal']); ax.yaxis.set_ticklabels(['high', 'low','normal']);"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  3   0   0]\n",
            " [  1  13   1]\n",
            " [ 49  81 124]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEWCAYAAABG030jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcHFW5//HPdzLZSAJh3xIIqwoI\nYVUMS1jFgCzK4gKicInAVcAF5Sr+EJRLLgoIwgXDIpusArLKLkuQQEJYQkC2QISQhD0rhGTm+f1R\nZ5LO3Fl6erqnp3q+77zqle6q6nOerq55+vSpU1WKCMzMLD/qqh2AmZl1jBO3mVnOOHGbmeWME7eZ\nWc44cZuZ5YwTt5lZzjhxd4KkjSV9VKW6D5E0XdI8SZ+rRgzdkaS9JL1a7ThaIul3kt6X9EYnyqja\nPldOkk6VdH6148irmkvcktZJyaxpCknzC57v2ImyZ0raoel5RLwcEYPLE3mHnQ0cEREDI+LF5rFZ\naSR9SdK9kmanJDte0rfLUO5GwDHARhExrNRyKrXPSeqX/lbeklRXML+vpA8lfVJkOUV9cUbEKRHx\ng87E3JPVXOKOiH+nZDYwIgam2VsUzHu0qgGWgaTewFrAlDKVV1f4x9rKOvXlqKs7kzQSuBe4G1gP\nWAU4Dti7DMWvC8yMiA/KUFYlzQd2K3i+H/BOOSvoCftSxUVETU9AABs2m9cf+APwJjAT+CPQNy1b\ng+wP9yPgfeDBNP9GoBFYAMwj+4P+LLC4oNzxwCnp/znAXcCKBcv/I9X5LvCzVPcOrcR9APBsKuff\nwC/S/BVS/UH2RzalpdjSujsCT6T3MgkY0SzW09LyT4AhLcQwE/hpqmNBmjcUuBV4D5gKHF2w/gjg\n6RTzTOCMNL8euAmYlWL5B/CZgtddB5wL3Jfe00PAasD/pvWnAJ9vFtfPgH8BHwBjCz6/vYBXC9Zt\nNd4W3u9E4Kx29qf/BF5L+8bNwOppfr/0mYxOyz8EzknL9gE+Tp/RPOCi5nEWvK8d2tmWzfe5ddJ+\n9gHwMnB4wbIxwF+Aa4G5wHPA8FbeV1P8JwNXFcy/A/gl8EnBvO+nbT8XeJXslx/Ays3e57w0bwxw\nDXB9es2had4l6XWHp9gHFOz7b1Hwt+Op2edV7QAq/gZbTtwXAn8FBpMlwnuAU9Kyc1ISqQf6ADsV\nvG6ZRNvCH9F44CVgA2AA8E/g12nZlumP8ItAX+A8YDGtJ+7dgE3JfhVtlf4w90rLmv7IhrQR2zCy\n5LJ7KmMU2RfGigWxTgU+A/QG6luIYSYwgax13x/oBUwGfp62zcZkXyo7p/WfBg5KjwcBX0iP64Hv\nAANT7BcC4wvquS7VtUWqZ1yK7ZBU5++AvzeL6+kU16opxpPTsiUJsb14m73XwWmbbt/GvjQq1b15\neh9jgXubfSY3A8uTtdg/AkY2j6ul580/wza2ZfN97gmyfbYvsE3aT0akZWPIvsz3SNviHOChVt5b\nU/yfJfuCHUj25TmDbN8tTNz7pvcnsv3rY2DTNt7XGGBh2n516TNekrjTOjeRfaGtnurfo9q5oztP\nNddV0p70M+1I4PiI+CgiZpPtRN9IqywiSwjrRMSnEfFIB6u4OCJei4j5ZF8Ow9P8g4CbImJ8RCwk\na9m0uv0j4oGImBIRjRExCbgB2LkDcRwO3BwR96cy7gJeAPYsWOeSiHgpIhZFxOJWyjknIt6OiI+B\nHYB+EfE/adu8DPyZZbfdxpJWjoi5EfFEei+LI+LKiJgXEZ8ApwLbSepXUM+NEfFsqudWYHZEXB8R\nDem9b9ksrnNTXO8CZwDfbCH29uIttHL6f0Yr2wHg28DYiHguvY+fAbtLWqNgnf+OiDkR8TrwCEs/\n/45qcVsWSv3mW5D9GlsYEROBK4DDClZ7MCLuS9vxqiLimUf2y+frwLfI9uFFhStExG0R8Xpk7gce\nJtvWbXk4Iu5K++LHLSwfTfaF8ABwXUTc1055PVqPS9xkSbk3MEXSR+kI/d/IWhcApwNvA/+Q9Kqk\nH3ew/JkFjxeQtVya6n2zaUFEzAFmt1aIpBGSHpb0rqTZwHfJ+lyLtS5waNN7TO9zmxRHkzdbfuky\nCtdZFxjWrMwfk3UvQfZlsTnwsqQnJH05vZd6SWdJmippDtnPbLE0WULWymrycQvPB7KswrimNXtf\nxcZbqKnvec0WljVZK9UFQER8RPYrau2CdVr7/DuqxW3ZQjzvNkuE08oQz5Vkv5C+kx4vQ9K+kp6U\n9EHaprvS/r7Z5r4WEe8DtwCbkB14tzb0xMQ9g6yLYoOIGJymFSJiZYCImB0Rx0fEumStjpMljUiv\n7cylFGcAQ5qeSFqerJumNTeQ9QkOjYgVgMvJkl1rmsf2JlmLenDBNCAizmnjNe2V+ybwr2ZlDoqI\nAwAi4sWIOITsS/A84GZJfYDvkf1c34XsPX82ldfW+2nP0ILH65B92TbXZrzLvMmID4GnyD7z1rxN\n9mUAgKTBZN0i00uIfz6wXEFZvYGVCuJpbVs2j2dVSf0L5q1TYjyF7ifrVuoXERMKF0gaQHZM5TfA\napGNcHmQpZ9la/tUm/uapO3IfjXdSPZ+rQ09LnFHxCLgMuBcSasoM1TSHrCkNbG+JJG1iBvIDrZA\n1gpcv8SqbwC+Lmnb9Ad4WkG5y0h1DwTej4hPJH2JrKulLc1juwI4SNJuknpJ6p8et9TaLNa4FN8J\nafhYvaTNJW2V5n8n/bRvINt2kaZBZAdA3yfr+/9tJ2JocpykNSWtApxE9iXXoXhb8FPgaEnHS1ox\n7RtbS7o6Lb8WOErSZqmbZwxZV8TMVspry4vASukz6U3WfVQ4DK+1bVnoVbI+/N+mYXtbkbXUr6YT\nIqKRrD+6pS+x/mS/WN8BGiXtC4wsWD4LWE1S0b80JC1HFvNPyH5ZfkbSESUF30P0uMSdnEDWWplI\n9kdxN7BhWvY5slEPc8n6KH8fEY+nZacDp6ef3R0agxoRTwMnkv0cnE7WAp9NdtCm+boBHA38XtJc\nsr7UG9upYpnYImIq2R/eqWQjKqYBx9OJzzx96Y0CvpTKe5fsQGPTH+k+wEsp5jOAg9NrLk3rziRL\nNONKjaHAdWSf0yupzDNLiLf5+g+RHQPYO63/HnA+cGdafkd6X7eR7T9rsGx/ctEi4j2yz+MvZCMo\nZqb6mrS2LQvLCLIv9E3S668HToyITm/fiJgcES+2EvdPgdvJvoj3JxvV0uRZsu0zLe2LKzUvowVn\nAS9ExJ9Tt89hZPv+sM69i9ql7LO3riZpRbJ+1bUioq0DYtaMpJnAgeVIUGZ51FNb3FWRumH6p5+R\nZwNPOGmbWUc5cXetg8h+0r5FduS/06dSm1nP464SM7OccYvbzCxnuu3FXgYsN8w/BSps4eJF7a9k\nlgOLP53emXMCAFj03tSic07vVdbvdH2d4Ra3mVnOdNsWt5lZl2psqHYERXPiNjMDaGjtOmvdjxO3\nmRmQnemfD07cZmYAjU7cZmb54ha3mVnO+OCkmVnOuMVtZpYv4VElZmY544OTZmY5464SM7Oc8cFJ\nM7OccYvbzCxnfHDSzCxnfHDSzCxfItzHbWaWL+7jNjPLGXeVmJnljFvcZmY505Cfe7A6cZuZgbtK\nzMxyx10lZmY54xa3mVnOOHGbmeVL+OCkmVnOuI/bzCxn3FViZpYzbnGbmeWMW9xmZjnjFreZWc4s\nzs+NFOqqHUDe9e3bl4cf+Rvjx/+dCRPv5Zcn/6jaIdWsL+85kinPP8K/XhjHz078z2qHU5N69DaO\nxuKnKnOLu5MWLlzIqK98i/nzF1BfX8/9D/yVe+95iAkTnq52aDWlrq6O8849nb1GfZO33prB+Mfv\n4vY77uXFF1+pdmg1o8dv4xz1cbvFXQbz5y8AoHfvenr3rieIKkdUe7bbdktee+0NXn/93yxatIgb\nbriVfb/65WqHVVN6/DbOUYu74olbUi9Ja0lap2mqdJ1dra6ujsfH38Ub057iwQfGMXHCM9UOqeas\ntfYavPnW20uevzV9BmuttUYVI6o9PX4bNzYWP1VZRRO3pB8Cs4D7gDvTdEcl66yGxsZGtv/iKDbe\naHu23mYLNtlk42qHZGYdlaMWd6X7uI8HPhMR7xezsqTRwGiAPr1Xor5+UCVjK7vZs+fwyCOPs8ce\nO/PCCy9XO5ya8vb0mQwdstaS50PWXpO3355ZxYhqT4/fxh5VssSbwOxiV46IsRGxTURsk5ekvcoq\nK7HCCssD0K9fX3bddQdeevm1KkdVeyZMfIYNN1yPYcOG0rt3bw4+eD9uv+PeaodVU3r8No4ofqqy\nirS4Jf04PZwKPCTpTmBh0/KIOLsS9VbDGmusxtiLz6JXXR11dXXcdPOd3P33B6sdVs1paGjg+BNO\n5q47r6FXXR2XX3G9f9WUWY/fxmXsu5Z0GbAP8E5EbJbmrQRcDwwD3gAOjogPJQk4FxgFLAC+GxGT\n2iw/KvDtIemUtpZHxKntlTFguWHV/1qrcQsX5+cylmZtWfzpdHW2jI//8quic07/b/+mzfok7QTM\nA64sSNxnAh9ExBhJJwErRsTPJY0CfkiWuL8AnBsRX2ir/Iq0uItJzGZm3UoZDzpGxCOShjWbvR8w\nMj2+AngI+Hmaf2VkrejxkgZLWjMiZrRWfkUPTkq6Hf7PoObZwETgTxHxSSXrNzMrWkND0asWDqRI\nxkbE2HZetnpBMp4JrJ4er012PLDJW2ledRI3WR/3qsC16fkhwFxgY+Bi4LAK129mVpwO9HGnJN1e\nom7r9SGp5O7gSifuL0XEtgXPb5c0ISK2lTSlwnWbmRWv8ifWzGrqApG0JvBOmj8dGFqw3pA0r1WV\nHg44sPBMyfR4YHr6aYXrNjMrXuVPwLkNODw9Phy4tWD+d5T5IjC7rf5tqHyL+yfAOEmvAQLWA46V\nNICsc97MrFuIxvINZJN0LdmByFUkvQWcAowBbpB0JDANODitfhfZiJJXyYYDfq+98iuauCPiLkkb\nAZ9Ns14qOCD5h0rWbWbWIWXsKomIb7ayaLcW1g2gQ9fQrdQJOLtGxIOSvtZs0QaSiIibK1GvmVnJ\nOjCqpNoq1eLeGXgQ+Gp63vQbROmxE7eZdS/d4Kp/xarUCThNZ04eA3yd7BTPprp8RqSZdT89PXEX\n+BvwETAJaOrbduI2s+6nG1w8qliVTtxDImKvCtdhZtZ5OWpxV3oc9z8lfb7CdZiZdV5jFD9VWaVG\nlUwm6xKpB74naSrZZV1FNvpl80rUa2ZWMo8qYZ8KlWtmVhGRo66SSo0qmVaJcs3MKqYbdIEUq9IH\nJ83M8qEb3AS4WE7cZmbgFreZWe4s9sFJM7N8cVeJmVnOuKvEzCxfevxwQDOz3HGL28wsZ5y4zcxy\nxqe8m5nlSznvOVlpTtxmZuCuEjOz3PGoEjOznHGL28wsZ5y4zczyJRrcVdJpixoWVzuEmrfh4LWq\nHULNmzp7RrVDsGK5xW1mli8eDmhmljdO3GZmOZOfLm4nbjMzgFicn8ztxG1mBm5xm5nljQ9Ompnl\njVvcZmb54ha3mVneuMVtZpYvkaOTtZ24zcyAKFOLW9JngOsLZq0P/D9gMHAU8G6a/4uIuKuUOuqK\nCOJrkgalxydJukHS8FIqMzPrtho7MLUhIl6KiOERMRzYGlgA3JIWn9O0rNSkDUUkbuDXETFX0peA\nUcBfgItKrdDMrDuKxuKnDtgNeC0ippUz1mISd9MdNPcB/hQRtwJ9yxmEmVm1dSRxSxotaWLBNLqV\nYr8BXFvw/AeSnpN0maQVS421mMQ9Q9IFwCHAXZL6FPk6M7PciAYVP0WMjYhtCqaxzctLuXJf4MY0\n60JgA2A4MAM4q9RYi0nABwMPA3tHxIfAKsBJpVZoZtYdVaCr5CvApIiYBRARsyKiISIagYuB7UqN\ntdVRJZKWL3h6d8G8ecBjpVZoZtYdRaPKXeQ3KegmkbRmRDTdWeMA4PlSC25rOOAUIIDCd9P0PIB1\nSq3UzKy7KddwQABJA4A9gO8XzD4zjcgL4I1myzqk1cQdEUNLLdTMLG8iytfijoj5wMrN5h1WrvKL\nOsgo6RuSfpEeD5G0dbkCMDPrDio0HLAiijkB53xgF6Dp22IBHsdtZjWmsUFFT9VWzCnvX4qIrSQ9\nDRARH6RhLmZmNaMCBycrppjEvUhSHVmHOpJWJlfX0TIza1+eEncxfdwXADcBq0o6FRgH/E9FozIz\n62IRxU/V1m6LOyKulPQUsHuadVBElDz+0MysO8pTi7vYy7r2AhaRdZf4dHczqznlHA5YacWMKvkl\n2dk/awFDgGsk/VelAzMz60oNDSp6qrZiWtzfAbaMiAUAkk4HngbOqGRgZmZdKU8t7mIS94xm69Wn\neWZmNaMm+rglnUPWp/0BMEXSPen5nsCErgnPzKxrdIfRIsVqq8XdNHJkCnBnwfzxlQvHzKw6aqLF\nHRGXdmUgZmbV1NCYnwFzxYwq2UDSdel2Oy83TV0RXF6M/dPveevNZ3h60v3VDqWmnP6HX/HYlHu4\n7eHrlsw77udHc+tD13DLg3/h0hv+yGqrr1LFCGtLT9+P83QCTjFfMZcDfya7DvdXgBtY9tbzPd6V\nV93IPl89tNph1JxbrruDo75x3DLzLr3gKvYb+S0O2PXbPHTvOI796X9UKbra09P348ZQ0VO1FZO4\nl4uIewAi4rWIOJksgVsybtwTfPjhR9UOo+ZMHP80sz+as8y8+fPmL3ncf7n+RHdo/tSInr4fR6jo\nqdqKGQ64MF1k6jVJRwPTgUHFFC7pN8AjwD/ThcXNOu2E/zqG/Q7em7lz5nH4146udjhWI/LUBiim\nxf0jYABwHDACOAo4osjyp5Ldd22ipCclnSVpv9ZWLrzlfWOD87y17A9nXMguW+7DHTfdzaFHHlzt\ncKxG1FRXSUQ8ERFzI+LfEXFYROwbEUXdLDgi/hwRR5DdiOFq4KD0f2vrL7nlfV2vAcW+B+uhbr/p\n7+yx967VDsNqRENjXdFTtbV1As4tpGtwtyQivtZe4ZIuATYBZgGPAgcCkzoepllm3fWGMu31NwHY\nba+def3VN6obkNWMHPWUtNnHfX4Zyl+Z7MqCH5GdgfleRCwuQ7ndylVXns9OO23PKqusxNTXJnDa\nb87i8suva/+F1qazLvot247YmhVXGsxDz9zBH88cy867j2DYBusS0cjbb87klBN9yZxy6en7cXfo\nAimWuuKovKTPAV8m6y/vFRFD2ntNn75D8vQFmEvrr7BmtUOoeVNn+7I+XeHThW91Ous+tsaBReec\nETP/WtUsX+z1uEsiaR9gR2AnYDDwIFmXiZlZt5Kn+zFWNHEDe5El6nMj4u0K12VmVrIgP10lRSdu\nSX0jYmFHCo+IH0haHdhW0lbAkxHxTkeDNDOrtMU56uMu5lol20maDLySnm8h6Y/FFC7pIOBJsmGA\nBwNPSDqwE/GamVVEoKKnaiumxX0esA/wN4CIeFbSLkWWfzKwbVMrW9KqwP3AX0uI1cysYmqtj7su\nIqZJy3zLNBRZfl2zrpH38c2Gzawb6g4t6WIVk7jflLQdEJJ6AT8Eir2s693pzjnXpueHAHd1PEwz\ns8qqtRb3MWTdJeuQnQF5f5rXrog4UdLXya5xAjA2Im4pJVAzs0pqqKUWd+rq+EapFUTETcBNpb7e\nzKwr5OjOZe0nbkkX08Jp/BExuo3XzG3pNWQ3Y4iIWL4jQZqZVVpjLbW4ybpGmvQDDgDebOsFEVHU\n9brNzLqLPF1jo5iukmVuUybpKmBcxSIyM6uCWjs42dx6wOrlDsTMrJoaVUNdJZI+ZOmviDqyy7Oe\nVMmgzMy6WrEnpxRD0hvA3FTs4ojYRtJKZDdaHwa8ARwcER+WUn6biVvZWTdbkN1nEqAxfHdWM6tB\nFRhVsktEvFfw/CTggYgYI+mk9PznpRTc5lmMKUnfFRENaXLSNrOa1IiKnkq0H3BFenwFsH+pBRVz\n+vkzkrYstQIzszyIDkyFNzZPU/Ph0QHcK+mpgmWrR0TTnTVm0oljhW3dc7I+3WZsS2CCpNeA+Swd\ni71VqZWamXU3HekqiYixwNg2VtkhIqZLWg24T9K/mr0+JJXcg9FWH/eTwFbAvqUWbmaWF+UcDhgR\n09P/76Qbr28HzJK0ZkTMkLQmUPK9CdpK3EoVv1Zq4WZmedFQpoOTkgaQXRl1bnq8J3AacBtwODAm\n/X9rqXW0lbhXlfTj1hZGxNmlVmpm1t2UscW9OnBLuhR2PXBNRNwtaQJwg6QjgWlkN5cpSVuJuxcw\nEHJ0Ar+ZWYnKlbgjYirZMOrm898HditHHW0l7hkRcVo5KjEz6+5ydMvJ9vu4zcx6glq5VklZmvRm\nZnlQzlPeK63VxB0RH3RlIGZm1VRTN1IwM+sJaqWrxMysx3DiNjPLmTxdQc+J28wM93GbmeVOTYwq\nqbaxq4ysdgg1b/+Rb1c7hJo34Nzr21/JuoXGHHWWdNvEbWbWlXxw0swsZ/LT3nbiNjMD3OI2M8ud\nxaXfkKbLOXGbmeGuEjOz3HFXiZlZzng4oJlZzuQnbTtxm5kB7ioxM8udhhy1uZ24zcxwi9vMLHfC\nLW4zs3xxi9vMLGc8HNDMLGfyk7aduM3MAFico9TtxG1mhg9Ompnljg9OmpnljFvcZmY54xa3mVnO\nNIRb3GZmueJx3GZmOeM+bjOznHEft5lZzuSpq6Su2gGYmXUH0YF/bZE0VNI/JL0gaYqk49P8X0ua\nLumZNI0qNVa3uM3MKOuoksXATyJikqRBwFOS7kvLzomI33e2AiduMzPK11USETOAGenxXEkvAmuX\npfDEXSVmZmQHJ4udJI2WNLFgGt1SmZKGAVsCT6RZP5D0nKTLJK1YaqxO3GZmdKyPOyLGRsQ2BdPY\n5uVJGgjcBJwQEXOAC4ENgOFkLfKzSo3VXSVmZpR3VImk3mRJ+y8RcTNARMwqWH4xcEep5Ttxd4Lq\nxD5//w0LZn7IA4efxRojNmHbX32Lut69eH/yGzz2k4uJhjyNDu1e+u51IH12GQURNLz5OgvG/g99\nRu5N372+Tq811mb29/cn5s2pdpi5c/J/n80jjz3JSisO5m9XXwTA78+/hIcfe4L63vUMXXtNfvuL\nH7P8oIFLXjNj5jvse+j3OfaIb/O9bx1YrdArKsp0cFKSgEuBFyPi7IL5a6b+b4ADgOdLrcNdJZ3w\nuf/Yi9mvvJ09kdjxD9/n4WPP59bd/ot5b73HhgftWN0Ac0wrrkKfLx/A3JOPZu5JR0JdHX2235WG\nl59n/hk/pfHdmdUOMbf2H7UHF53922Xmbb/tltxy1UXccuWFDBu6Npdcdf0yy8/841h2/OI2XRlm\nl2sgip7aMQI4DNi12dC/MyVNlvQcsAvwo1JjdeIu0XJrrsSQ3Ybz8rUPAdB3xYE0fLqYOVOzhPL2\nI8+z7qhtqxhh/qlXL9SnL9TVob59afzwfRqmvUrje7Paf7G1apvhn2eF5QctM2/EF7amvr4XAJtv\n+llmvfPekmUPPPJP1l5zDTZYb90ujbOrNRJFT22JiHERoYjYPCKGp+muiDgsIj6f5u9b0PruMCfu\nEm136qE89dtroTH7EBd+MJe6+l6svPl6AAzbezsGrLVyNUPMtfjwPT658waWP+86lr/gr8SC+Sye\nPLHaYfUIt9x5LztsnzU6Fiz4mMuuvpFjj/h2laOqvIgoeqq2ivRxS9qqreURMakS9XaVIbsP55P3\n5vD+5DdYY/vPLZn/8LHns92vD6WuTz1vPzKZaHT/dqm03EB6bz2COSd8i1gwjwHHnULvEbuz6LH7\nqx1aTfvTFdfSq1cv9tlzFwAuuOxqDjvkAJZbrn+VI6u8PJ3yXqmDk20Ncwlg15YWpLGQowEOX2E7\nRg7YqAKhdd5q22zM0D23YsiuW9Crb296D+rPjucdw6PHXcjfv/YbANbaaTOWX3/NKkeaX/WbbU3j\nuzOIubMB+HTCo9RvtKkTdwX97c77eOSxJ7nkvDPIjq/B5Ckvcd8/xnH2/17K3HnzkUTfPn341oH7\nVjna8uvxVweMiF1KfN1YYCzA5Wsf2m234qQxNzBpzA0ArLH959j06FE8etyF9Ft5eT55fw51ferZ\n7D+/ynPn3VrlSPOr8f1Z1G+4CfTpC58upPemW7H49ZerHVbNGjd+IpddcyOXn38m/fv1WzL/yguX\nnp19waVXs1z/fjWZtME3UliGpM2ATYAle0NEXFnpeqths2P2Zsjuw1FdHS9deT8zH3uh2iHlVsNr\n/2LRkw8z6PQ/QUMDDdNe5dMH76DPlw+g3z7fQCusxKAxl7DomSf4+JKSz2PokU48ZQwTnn6Ojz6a\nw277H8qxRx7GJVddz6eLFnHUCb8EsgOUp/zsh1WOtGvlqatElexol3QKMJIscd8FfAUYFxHtDgTt\nzi3uWrH/yLerHULNG3DuJdUOoUfovcr66mwZ26+9S9E55/Hp/+h0fZ1R6VElBwK7ATMj4nvAFsAK\nFa7TzKzDevyokgIfR0SjpMWSlgfeAYZWuE4zsw7LU1dJpRP3REmDgYuBp4B5wOMVrtPMrMN6/KiS\nJhFxbHp4kaS7geUj4rlK1mlmVoqGyM95F10xqmRzYFhTXZI2bLpalplZd9Ed+q6LVdHELekyYHNg\nCktvohyAE7eZdSvu417qixGxSYXrMDPrtDz1cVd6OODjkpy4zazba4woeqq2Sre4ryRL3jOBhYCA\niIjNK1yvmVmH5KnFXenEfSnZBcUns7SP28ys2/GokqXejYjbKlyHmVmndYcukGJVOnE/Leka4Hay\nrhIAPBzQzLobd5Us1Z8sYe9ZMM/DAc2s23GLG5DUC3guIs6pVB1mZuWSpxZ3xYYDRkQD8M1KlW9m\nVk4N0VD0VG2V7ip5TNL5wPXA/KaZeb/npJnVHp/yvtTw9P9pBfNaveekmVm1+JT3pNR7T5qZdTW3\nuBNJKwCnADulWQ8Dp0XE7ErWa2bWUXkaVVLpa5VcBswFDk7THODPFa7TzKzDogP/qq3SfdwbRMTX\nC56fKumZCtdpZtZheTrlvdIt7o8l7dD0RNII4OMK12lm1mG+WfBSxwBXpL5ugA+Bwytcp5lZh+Wp\nj7vSiftF4ExgA2AwMBvYH/DuMasrAAAHiElEQVR9J82sW+kOLeliVTpx3wp8BEwCple4LjOzknkc\n91JDImKvCtdhZtZpbnEv9U9Jn4+IyRWux8ysU/I0qqTSiXsH4LuSXse3LjOzbswHJ5f6SoXLNzMr\nC3eVJBExrZLlm5mVSznPiJS0F3Au0Au4JCLGlK1wKt/iNjPLhXK1uNNNZC4A9gDeAiZIui0iXihL\nBThxm5kBZe3j3g54NSKmAki6DtgPqP3E/d3pV6vaMXSUpNERMbbacdQyb+PK66nbePGn04vOOZJG\nA6MLZo0t2GZrA28WLHsL+ELnI1yq0tcq6WlGt7+KdZK3ceV5G7cjIsZGxDYFU5d+0Tlxm5mV13Rg\naMHzIZT5zHEnbjOz8poAbCRpPUl9gG8At5Wzgm7bx51TPa5fsAq8jSvP27gTImKxpB8A95ANB7ws\nIqaUsw7ladC5mZm5q8TMLHecuM3McsaJuwiShkl6voX5p0navZ3X/lrSTysXXe2RNK/aMVjpJD0k\naZtqx1HLfHCyEyLi/1U7BrNyklQfEYurHYe1zS3u4vWSdLGkKZLuldRf0uWSDgSQNErSvyQ9Jek8\nSXcUvHaT1AqZKum4KsWfO8r8TtLzkiZLOiTNv0DSvunxLZIuS4+PkHR6NWPuDtIvxBdb2F+HSxov\n6bm03VZM6z8k6Q+SJgLHp/36wrTuVEkjJV2Wyry8oJ4LJU1MdZxarffbEzlxF28j4IKI2JTsdmxf\nb1ogqR/wJ+ArEbE1sGqz134W+DLZNQxOkdS7a0LOva8Bw4EtgN2B30laE3gU2DGtszawSXq8I/BI\nVwfZTbW0v14J/DxdD38ycErB+n3SGYBnpecrAtsDPyIbg3wOsCnweUnD0zq/jIhtgM2BnSX5Ovtd\nxIm7eK9HxDPp8VPAsIJlnwWmRsTr6fm1zV57Z0QsjIj3gHeA1Ssaae3YAbg2IhoiYhbwMLAtKXFL\n2oTswj2zUkLfHvhn1aLtXprvrxsAgyPi4TTvCmCngvWvb/b62yMbKzwZmBURkyOiEZjC0n3/YEmT\ngKfJkvomWJdwH3fxFhY8bgD6d+K13u6dEBHTJQ0G9iJrYa8EHAzMi4i5VQ2u+2i+zw1uZ/35rby+\nsVlZjUC9pPWAnwLbRsSHqQulX+nhWke4xV0eLwHrSxqWnh9SvVBqyqPAIZJ6SVqVrIX4ZFo2HjiB\nLHE/SpZEHq1KlPkwG/hQUlMX02Fkv2BKtTxZsp8taXV8t6su5ZZfGUTEx5KOBe6WNJ/sWgXWebeQ\ndX88CwTws4iYmZY9CuwZEa9KmkbW6nbibtvhwEWSlgOmAt8rtaCIeFbS08C/yC5h+lh5QrRi+JT3\nMpE0MCLmSRLZ3S9eiYhzqh2XmdUed5WUz1GSniE7eLMC2SgTM7Oyc4vbzCxn3OI2M8sZJ24zs5xx\n4jYzyxknbvs/JDVIeiZdI+TGNHys1LJGNl23RdK+kk5qY93BaVhlR+to8QqMxVyZsfB6M0XW1eKV\nIs26khO3teTjiBgeEZsBnwJHFy5MF3/q8L4TEbdFxJg2VhkMdDhxm/U0TtzWnkeBDVNL8yVJVwLP\nA0Ml7SnpcUmTUst8IICkvdKVEieRXSiKNP+7ks5Pj1dPV6h7Nk1fAsYAG6TW/u/SeidKmpCuaHdq\nQVm/lPSypHHAZ9p7E5KOSuU8K+mmZr8idk9XuXtZ0j5p/V7pyoRNdX+/hTI3lfRkivc5SRt1fPOa\ndZwTt7VKUj3ZqcyT06yNgP9NV5ybD5wM7B4RWwETgR+nKyVeDHwV2BpYo5XizwMejogtgK3Ixr+f\nBLyWWvsnStoz1bkd2VUCt5a0k6Stye6cPRwYRXbhqfbcHBHbpvpeBI4sWDYs1bE32ZmF/dLy2RGx\nbSr/qHR9jkJHA+dGxHBgG+CtIuIw6zSf8m4t6Z9OJoKsxX0psBYwLSLGp/lfJLsa3GPZyaL0AR4n\nu1Li6xHxCoCkq4HRLdSxK/AdgIhoILvmxYrN1tkzTU+n5wPJEvkg4JaIWJDquK2I97SZpN+SdccM\nJLsDd5Mb0pXvXpE0Nb2HPYHNC/q/V0h1v1zwuseBX0oaQvbF8EoRcZh1mhO3teTj1IpcIiXnwivI\nCbgvIr7ZbL1lXtdJAs6IiGXOQpV0QgllXQ7sn66x8V1gZMGy5mehRar7hxFRmOApuJAYEXGNpCfI\nWup3Sfp+RDxYQmxmHeKuEivVeGCEpA0BJA2QtDHZRYeGSdogrffNVl7/AHBMem0vSSsAc8la003u\nAY4o6DtfW9JqZFcE3F/ZXV0GkXXLtGcQMCPdxOLbzZYdJKkuxbw+2dUe7wGOSesjaWNJAwpfJGl9\nsuuwnwfcSnZDAbOKc4vbShIR76aW67WS+qbZJ0fEy5JGA3dKWkDW1TKohSKOB8ZKOpLsetHHRMTj\nkh5Lw+3+nvq5Pwc8nlr884BDI2KSpOvJrhr4DsVdjfFXwBPAu+n/wpj+TXa52OWBoyPiE0mXkPV9\nT0oXDnsX2L9ZmQcDh0laBMwE/ruIOMw6zdcqMTPLGXeVmJnljBO3mVnOOHGbmeWME7eZWc44cZuZ\n5YwTt5lZzjhxm5nlzP8H8ERahcoy8+MAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpUC_BjKtbo4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}